// THIS IS AUTO GENERATED, ONLY EDIT THE TEMPLATE

// Copyright Cartesi and individual authors (see AUTHORS)
// SPDX-License-Identifier: Apache-2.0
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

pragma solidity ^0.8.0;

import "forge-std/StdJson.sol";
import "forge-std/console.sol";
import "forge-std/Test.sol";

import "ready_src/UArchStep.sol";
import "./BufferAux.sol";

contract UArchReplay_@X@_Test is Test {
    using Buffer for Buffer.Context;
    using BufferAux for Buffer.Context;
    using stdJson for string;

    // configure the tests
    string constant JSON_PATH = "./test/uarch-log/";
    string constant CATALOG_PATH = "catalog.json";

    uint256 constant siblingsLength = 61;

    struct Entry {
        string path;
        bool proof;
        uint256 proofsFrequency;
        uint256 steps;
    }

    struct RawAccess {
        uint256 position;
        RawProof rawProof;
        string accessType;
        string val;
    }

    struct RawProof {
        uint256 log2Root;
        uint256 log2Target;
        string rootHash;
        string[] rawSiblings;
        uint256 targetPosition;
        string targetHash;
    }

    struct Proof {
        bytes32 targetHash;
        bytes32[] siblings;
    }

    function testReplay_@X@() public {
        Entry[] memory catalog = loadCatalog(
            string.concat(JSON_PATH, CATALOG_PATH)
        );

        // all tests combined can easily run out of gas, stop metering
        // also raise memory_limit in foundry.toml per https://github.com/foundry-rs/foundry/issues/3971
        vm.pauseGasMetering();
        // create a large buffer and reuse it
        bytes memory buffer = new bytes(100 * (siblingsLength + 1) * 32);

        for (uint256 i = 0; i < catalog.length; i++) {
            if (keccak256(abi.encodePacked(catalog[i].path)) !=
                keccak256(abi.encodePacked("@PATH@"))) {
                continue;
            }
            console.log("Replaying file %s ...", catalog[i].path);
            require(catalog[i].proofsFrequency == 1, "require proof in every step");

            string memory rj = loadJsonLog(
                string.concat(JSON_PATH, catalog[i].path)
            );
            for (uint256 j = 0; j < catalog[i].steps; j++) {
                console.log("Replaying step %d ...", j);
                // load json log
                bytes32 rootHash = loadBufferFromRawJson(buffer, rj, j);

                UArchStep.step(AccessLogs.Context(rootHash, Buffer.Context(buffer, 0)));
            }
        }
    }

    function loadCatalog(
        string memory path
    ) private view returns (Entry[] memory) {
        string memory json = vm.readFile(path);
        bytes memory raw = json.parseRaw("");
        Entry[] memory catalog = abi.decode(raw, (Entry[]));

        return catalog;
    }

    function loadJsonLog(
        string memory path
    ) private view returns (string memory) {
        return vm.readFile(path);
    }

    function loadBufferFromRawJson(
        bytes memory data,
        string memory rawJson,
        uint256 stepIndex
    ) private pure returns (bytes32) {
        string memory key = string.concat(
            string.concat(".steps[", vm.toString(stepIndex)),
            "].accesses"
        );
        bytes memory raw = rawJson.parseRaw(key);
        RawAccess[] memory rawAccesses = abi.decode(raw, (RawAccess[]));

        uint256 readCount = 0;
        uint256 arrayLength = rawAccesses.length;

        for (uint256 i = 0; i < arrayLength; i++) {
            if (
                keccak256(abi.encodePacked(rawAccesses[i].accessType)) ==
                keccak256(abi.encodePacked("read"))
            ) {
                readCount++;
            }
        }

        Buffer.Context memory buffer = Buffer.Context(data, 0);

        for (uint256 i = 0; i < arrayLength; i++) {
            if (
                keccak256(abi.encodePacked(rawAccesses[i].accessType)) ==
                keccak256(abi.encodePacked("read"))
            ) {
                bytes8 word = bytes8(
                    vm.parseBytes32(string.concat("0x", rawAccesses[i].val))
                );
                buffer.writeBytes8(word);
            }

            buffer.writeBytes32(
                vm.parseBytes32(
                    string.concat("0x", rawAccesses[i].rawProof.targetHash)
                )
            );

            for (
                uint256 j = i * (siblingsLength + 1) + 1;
                j < (i + 1) * (siblingsLength + 1);
                j++
            ) {
                // proofs should be loaded in reverse order
                buffer.writeBytes32(
                    vm.parseBytes32(
                        string.concat(
                            "0x",
                            rawAccesses[i].rawProof.rawSiblings[
                                siblingsLength - (j % (siblingsLength + 1))
                            ]
                        )
                    )
                );
            }
        }

        for (uint256 i = 0; i < arrayLength; i++) {
            if (
                keccak256(abi.encodePacked(rawAccesses[i].accessType)) ==
                keccak256(abi.encodePacked("read"))
            ) {
                readCount++;
            }
        }

        return
            vm.parseBytes32(
                string.concat("0x", rawAccesses[0].rawProof.rootHash)
            );
    }
}
